# LT_Project
Language Technology Project

1) Our target would be... train the Persian treebank on both the Perser.

2) Build a model for each

3) Test the test_data using those models

4) Give test output scores

5) Give the test output (parser output) and if it's not correct to provide the correct output (Gold Label)

6) See if the other Parser outputted the correct one or not... If not then we will preserve this example (for re-training purpose or for using it on our future  combined parsers or whatever*)

7) give me the output of UDpipe & Spacy persers  like this: 

                        label(head_word,dependent_word)

So that we may easily compare or report them (where the problem is)
